{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":33657,"databundleVersionId":3279164,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":12953907,"sourceType":"datasetVersion","datasetId":8198177}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook is a copy of [Jeremy Howard's, Getting started with NLP for absolute beginners](https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners/notebook). Here we have explored deberta-v3-model from the huggingface library.","metadata":{}},{"cell_type":"code","source":"import os\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:08.005441Z","iopub.execute_input":"2025-09-03T20:46:08.005677Z","iopub.status.idle":"2025-09-03T20:46:08.014421Z","shell.execute_reply.started":"2025-09-03T20:46:08.005654Z","shell.execute_reply":"2025-09-03T20:46:08.013646Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from pathlib import Path\n\nif iskaggle:\n    path = Path('../input/us-patent-phrase-to-phrase-matching')\n    ! pip install -q datasets\n\n    path2 = Path('../input/deberta-v3-small/deberta-v3-small')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:08.016505Z","iopub.execute_input":"2025-09-03T20:46:08.017010Z","iopub.status.idle":"2025-09-03T20:46:11.369456Z","shell.execute_reply.started":"2025-09-03T20:46:08.016989Z","shell.execute_reply":"2025-09-03T20:46:11.368661Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Import Data and EDA","metadata":{}},{"cell_type":"code","source":"!ls {path}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:11.370405Z","iopub.execute_input":"2025-09-03T20:46:11.370633Z","iopub.status.idle":"2025-09-03T20:46:11.490553Z","shell.execute_reply.started":"2025-09-03T20:46:11.370609Z","shell.execute_reply":"2025-09-03T20:46:11.489959Z"}},"outputs":[{"name":"stdout","text":"sample_submission.csv  test.csv  train.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!ls {path2}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:11.491420Z","iopub.execute_input":"2025-09-03T20:46:11.491614Z","iopub.status.idle":"2025-09-03T20:46:11.611303Z","shell.execute_reply.started":"2025-09-03T20:46:11.491593Z","shell.execute_reply":"2025-09-03T20:46:11.610689Z"}},"outputs":[{"name":"stdout","text":"config.json    pytorch_model.bin  spm.model    tokenizer_config.json\ngitattributes  README.md\t  tf_model.h5\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:11.612229Z","iopub.execute_input":"2025-09-03T20:46:11.612487Z","iopub.status.idle":"2025-09-03T20:46:11.924303Z","shell.execute_reply.started":"2025-09-03T20:46:11.612455Z","shell.execute_reply":"2025-09-03T20:46:11.923771Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df = pd.read_csv(path/'train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:11.924969Z","iopub.execute_input":"2025-09-03T20:46:11.925209Z","iopub.status.idle":"2025-09-03T20:46:11.982940Z","shell.execute_reply.started":"2025-09-03T20:46:11.925194Z","shell.execute_reply":"2025-09-03T20:46:11.982396Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:11.983897Z","iopub.execute_input":"2025-09-03T20:46:11.984091Z","iopub.status.idle":"2025-09-03T20:46:11.996518Z","shell.execute_reply.started":"2025-09-03T20:46:11.984076Z","shell.execute_reply":"2025-09-03T20:46:11.995726Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                     id        anchor                  target context  score\n0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50\n1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75\n2      36d72442aefd8232     abatement         active catalyst     A47   0.25\n3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50\n4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00\n...                 ...           ...                     ...     ...    ...\n36468  8e1386cbefd7f245  wood article          wooden article     B44   1.00\n36469  42d9e032d1cd3242  wood article              wooden box     B44   0.50\n36470  208654ccb9e14fa3  wood article           wooden handle     B44   0.50\n36471  756ec035e694722b  wood article         wooden material     B44   0.75\n36472  8d135da0b55b8c88  wood article        wooden substrate     B44   0.50\n\n[36473 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>37d61fd2272659b1</td>\n      <td>abatement</td>\n      <td>abatement of pollution</td>\n      <td>A47</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7b9652b17b68b7a4</td>\n      <td>abatement</td>\n      <td>act of abating</td>\n      <td>A47</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36d72442aefd8232</td>\n      <td>abatement</td>\n      <td>active catalyst</td>\n      <td>A47</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5296b0c19e1ce60e</td>\n      <td>abatement</td>\n      <td>eliminating process</td>\n      <td>A47</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54c1e3b9184cb5b6</td>\n      <td>abatement</td>\n      <td>forest region</td>\n      <td>A47</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36468</th>\n      <td>8e1386cbefd7f245</td>\n      <td>wood article</td>\n      <td>wooden article</td>\n      <td>B44</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>36469</th>\n      <td>42d9e032d1cd3242</td>\n      <td>wood article</td>\n      <td>wooden box</td>\n      <td>B44</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>36470</th>\n      <td>208654ccb9e14fa3</td>\n      <td>wood article</td>\n      <td>wooden handle</td>\n      <td>B44</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>36471</th>\n      <td>756ec035e694722b</td>\n      <td>wood article</td>\n      <td>wooden material</td>\n      <td>B44</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>36472</th>\n      <td>8d135da0b55b8c88</td>\n      <td>wood article</td>\n      <td>wooden substrate</td>\n      <td>B44</td>\n      <td>0.50</td>\n    </tr>\n  </tbody>\n</table>\n<p>36473 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"df.describe(include='object')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:11.999313Z","iopub.execute_input":"2025-09-03T20:46:11.999503Z","iopub.status.idle":"2025-09-03T20:46:12.048802Z","shell.execute_reply.started":"2025-09-03T20:46:11.999487Z","shell.execute_reply":"2025-09-03T20:46:12.048215Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                      id                       anchor       target context\ncount              36473                        36473        36473   36473\nunique             36473                          733        29340     106\ntop     8d135da0b55b8c88  component composite coating  composition     H01\nfreq                   1                          152           24    2186","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>36473</td>\n      <td>36473</td>\n      <td>36473</td>\n      <td>36473</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>36473</td>\n      <td>733</td>\n      <td>29340</td>\n      <td>106</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>8d135da0b55b8c88</td>\n      <td>component composite coating</td>\n      <td>composition</td>\n      <td>H01</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>152</td>\n      <td>24</td>\n      <td>2186</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"We can observe that from 36473 anchor only 733 are unique and about 30k unique target.","metadata":{}},{"cell_type":"markdown","source":"For input to the model, we can concatenate anchor, target and context together, call that a model and then try to predict the scores. Take a similarity problem and turn it into something that looks like a classification problem. It's like looking at a problem which looks novel or different and turn them into something that we recognize.","metadata":{}},{"cell_type":"code","source":"df['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:12.049396Z","iopub.execute_input":"2025-09-03T20:46:12.049607Z","iopub.status.idle":"2025-09-03T20:46:12.070096Z","shell.execute_reply.started":"2025-09-03T20:46:12.049562Z","shell.execute_reply":"2025-09-03T20:46:12.069311Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df.input.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:12.070771Z","iopub.execute_input":"2025-09-03T20:46:12.071001Z","iopub.status.idle":"2025-09-03T20:46:12.082832Z","shell.execute_reply.started":"2025-09-03T20:46:12.070985Z","shell.execute_reply":"2025-09-03T20:46:12.082111Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0    TEXT1: A47; TEXT2: abatement of pollution; ANC...\n1    TEXT1: A47; TEXT2: act of abating; ANC1: abate...\n2    TEXT1: A47; TEXT2: active catalyst; ANC1: abat...\n3    TEXT1: A47; TEXT2: eliminating process; ANC1: ...\n4    TEXT1: A47; TEXT2: forest region; ANC1: abatement\nName: input, dtype: object"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# Tokenization","metadata":{}},{"cell_type":"markdown","source":"A deep learning model expects numbers as inputs, so we need to do :\n* Tokeanization: Split ach text into words/ tokens\n* Numericalization: Convert each word/ token into numbers\n\nTo convert the input into tokens, we are going to convert the pandas dataframe into HuggingFace \"Dataset\".","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset,DatasetDict\n\nds = Dataset.from_pandas(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:12.083703Z","iopub.execute_input":"2025-09-03T20:46:12.083969Z","iopub.status.idle":"2025-09-03T20:46:12.600762Z","shell.execute_reply.started":"2025-09-03T20:46:12.083948Z","shell.execute_reply":"2025-09-03T20:46:12.599968Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:12.601598Z","iopub.execute_input":"2025-09-03T20:46:12.601936Z","iopub.status.idle":"2025-09-03T20:46:12.606940Z","shell.execute_reply.started":"2025-09-03T20:46:12.601918Z","shell.execute_reply":"2025-09-03T20:46:12.606147Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'anchor', 'target', 'context', 'score', 'input'],\n    num_rows: 36473\n})"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"We need to choose a model with similar tokens and numericalization from Hugging Face library.","metadata":{}},{"cell_type":"code","source":"model_nm = 'microsoft/deberta-v3-small'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:12.607779Z","iopub.execute_input":"2025-09-03T20:46:12.608282Z","iopub.status.idle":"2025-09-03T20:46:12.618342Z","shell.execute_reply.started":"2025-09-03T20:46:12.608258Z","shell.execute_reply":"2025-09-03T20:46:12.617613Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"To tell transformers that we want to tokenize the same way that the people that built a model did, we use something called AutoTokenizer. AutoTokenizer will create a tokenizer appropriate for a given model. “AutoTokenizer.from_pretrained” will download the vocabulary and the details about how this particular model tokenized the dataset.","metadata":{"execution":{"iopub.status.busy":"2025-09-01T08:52:24.356064Z","iopub.execute_input":"2025-09-01T08:52:24.356950Z","iopub.status.idle":"2025-09-01T08:52:24.361645Z","shell.execute_reply.started":"2025-09-01T08:52:24.356926Z","shell.execute_reply":"2025-09-01T08:52:24.360793Z"}}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification,AutoTokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:12.619121Z","iopub.execute_input":"2025-09-03T20:46:12.619422Z","iopub.status.idle":"2025-09-03T20:46:15.890510Z","shell.execute_reply.started":"2025-09-03T20:46:12.619404Z","shell.execute_reply":"2025-09-03T20:46:15.889698Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# !rm -r models\n# !ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:15.891379Z","iopub.execute_input":"2025-09-03T20:46:15.891829Z","iopub.status.idle":"2025-09-03T20:46:15.895415Z","shell.execute_reply.started":"2025-09-03T20:46:15.891808Z","shell.execute_reply":"2025-09-03T20:46:15.894489Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# !ls models/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:15.896287Z","iopub.execute_input":"2025-09-03T20:46:15.896638Z","iopub.status.idle":"2025-09-03T20:46:15.907264Z","shell.execute_reply.started":"2025-09-03T20:46:15.896618Z","shell.execute_reply":"2025-09-03T20:46:15.906737Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# def setup_for_offline_use():\n#     model_name = 'microsoft/deberta-v3-small'\n#     local_dir = \"deberta-v3-small\"\n    \n#     tokz = AutoTokenizer.from_pretrained(model_name)\n#     model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n    \n#     tokz.save_pretrained(local_dir)\n#     model.save_pretrained(local_dir)\n    \n#     return tokz, model\n\n# # Run this once with internet\n# tokz, model = setup_for_offline_use()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:15.908063Z","iopub.execute_input":"2025-09-03T20:46:15.908324Z","iopub.status.idle":"2025-09-03T20:46:15.917883Z","shell.execute_reply.started":"2025-09-03T20:46:15.908302Z","shell.execute_reply":"2025-09-03T20:46:15.917235Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def offline_load_model():\n    # path_to_zip_file = \"../input/deberta-v3-small.zip\"\n    local_dir = \"../input/deberta-v3-small/deberta-v3-small\"\n    \n    # import zipfile\n    # with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n    #   zip_ref.extractall(local_dir)\n    \n    \n    if not os.path.exists(local_dir):\n        raise FileNotFoundError(f\"Model directory {local_dir} not found. Run setup_for_offline_use() first with internet.\")\n    \n    tokz = AutoTokenizer.from_pretrained(local_dir, local_files_only=True)\n    model = AutoModelForSequenceClassification.from_pretrained(local_dir, num_labels=1, local_files_only=True)\n    \n    return tokz, model\n\n# This works offline\ntokz, model = offline_load_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:15.918466Z","iopub.execute_input":"2025-09-03T20:46:15.918624Z","iopub.status.idle":"2025-09-03T20:46:23.547474Z","shell.execute_reply.started":"2025-09-03T20:46:15.918611Z","shell.execute_reply":"2025-09-03T20:46:23.546603Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n2025-09-03 20:46:20.054318: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756932380.076182    3382 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756932380.083249    3382 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nSome weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ../input/deberta-v3-small/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"tokz.tokenize(\"Hi, we are using Huggingface transformers for out NLP model!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:23.548376Z","iopub.execute_input":"2025-09-03T20:46:23.549058Z","iopub.status.idle":"2025-09-03T20:46:23.555080Z","shell.execute_reply.started":"2025-09-03T20:46:23.549035Z","shell.execute_reply":"2025-09-03T20:46:23.554200Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"['▁Hi',\n ',',\n '▁we',\n '▁are',\n '▁using',\n '▁Hugg',\n 'ing',\n 'face',\n '▁transformers',\n '▁for',\n '▁out',\n '▁NLP',\n '▁model',\n '!']"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"Uncommon words will be split into pieces. The start of a new word is represented by ▁:","metadata":{}},{"cell_type":"code","source":"tokz.tokenize(\"Sometimes I get intoxicated by the exuberance of my own verbosity\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:23.555874Z","iopub.execute_input":"2025-09-03T20:46:23.556136Z","iopub.status.idle":"2025-09-03T20:46:23.567399Z","shell.execute_reply.started":"2025-09-03T20:46:23.556118Z","shell.execute_reply":"2025-09-03T20:46:23.566649Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"['▁Sometimes',\n '▁I',\n '▁get',\n '▁intoxicated',\n '▁by',\n '▁the',\n '▁exuberance',\n '▁of',\n '▁my',\n '▁own',\n '▁verb',\n 'osity']"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# Function which takes input and tokenize it\ndef tok_func(x): return tokz(x[\"input\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:23.568218Z","iopub.execute_input":"2025-09-03T20:46:23.568427Z","iopub.status.idle":"2025-09-03T20:46:23.576816Z","shell.execute_reply.started":"2025-09-03T20:46:23.568411Z","shell.execute_reply":"2025-09-03T20:46:23.576125Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# To run this parallely to every row in our dataset, we use map:\ntok_ds = ds.map(tok_func, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:23.577586Z","iopub.execute_input":"2025-09-03T20:46:23.577812Z","iopub.status.idle":"2025-09-03T20:46:25.251424Z","shell.execute_reply.started":"2025-09-03T20:46:23.577795Z","shell.execute_reply":"2025-09-03T20:46:25.250773Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/36473 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc15af00ac2446f2ba3a2191d3b952c5"}},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"This will add a new row to our dataset, e.g., first row in our dataset:","metadata":{}},{"cell_type":"code","source":"row = tok_ds[0]\nrow['input'], row['input_ids']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:25.252467Z","iopub.execute_input":"2025-09-03T20:46:25.252835Z","iopub.status.idle":"2025-09-03T20:46:25.258746Z","shell.execute_reply.started":"2025-09-03T20:46:25.252809Z","shell.execute_reply":"2025-09-03T20:46:25.257854Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"('TEXT1: A47; TEXT2: abatement of pollution; ANC1: abatement',\n [1,\n  54453,\n  435,\n  294,\n  336,\n  5753,\n  346,\n  54453,\n  445,\n  294,\n  47284,\n  265,\n  6435,\n  346,\n  23702,\n  435,\n  294,\n  47284,\n  2])"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"This numbers come from a list called vocab in the tokenizer, which contains a unique integer for every possible token string.","metadata":{}},{"cell_type":"code","source":"tokz.vocab['▁of'], tokz.vocab['of']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:25.259395Z","iopub.execute_input":"2025-09-03T20:46:25.259595Z","iopub.status.idle":"2025-09-03T20:46:25.445674Z","shell.execute_reply.started":"2025-09-03T20:46:25.259573Z","shell.execute_reply":"2025-09-03T20:46:25.444905Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"(265, 1580)"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"Transformers assumes that the labels have the column name labels, but in this dataset it is score, therefore, we need to rename it.","metadata":{}},{"cell_type":"code","source":"tok_ds = tok_ds.rename_columns({'score':'labels'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:25.446555Z","iopub.execute_input":"2025-09-03T20:46:25.446856Z","iopub.status.idle":"2025-09-03T20:46:25.458094Z","shell.execute_reply.started":"2025-09-03T20:46:25.446836Z","shell.execute_reply":"2025-09-03T20:46:25.457407Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"Now we have created our tokens and labels, we need to create a validation set.","metadata":{}},{"cell_type":"markdown","source":"# Test and Validation sets","metadata":{}},{"cell_type":"code","source":"eval_df = pd.read_csv(path/'test.csv')\neval_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:25.461989Z","iopub.execute_input":"2025-09-03T20:46:25.462248Z","iopub.status.idle":"2025-09-03T20:46:25.484010Z","shell.execute_reply.started":"2025-09-03T20:46:25.462233Z","shell.execute_reply":"2025-09-03T20:46:25.483282Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                      id          anchor                         target  \\\ncount                 36              36                             36   \nunique                36              34                             36   \ntop     4112d61851461f60  hybrid bearing  inorganic photoconductor drum   \nfreq                   1               2                              1   \n\n       context  \ncount       36  \nunique      29  \ntop        G02  \nfreq         3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>36</td>\n      <td>36</td>\n      <td>36</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>36</td>\n      <td>34</td>\n      <td>36</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>4112d61851461f60</td>\n      <td>hybrid bearing</td>\n      <td>inorganic photoconductor drum</td>\n      <td>G02</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"Transformers uses a DatasetDict for holding your training and validation sets. To create one that contains 25% of our data for the validation set, and 75% for the training set, use train_test_split:","metadata":{}},{"cell_type":"code","source":"# train and validation set\ndds = tok_ds.train_test_split(0.25, seed=42)\ndds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:25.484788Z","iopub.execute_input":"2025-09-03T20:46:25.485035Z","iopub.status.idle":"2025-09-03T20:46:25.503166Z","shell.execute_reply.started":"2025-09-03T20:46:25.485014Z","shell.execute_reply":"2025-09-03T20:46:25.502449Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 27354\n    })\n    test: Dataset({\n        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 9119\n    })\n})"},"metadata":{}}],"execution_count":27},{"cell_type":"markdown","source":"Here, validation set is named as test and not as valid.","metadata":{}},{"cell_type":"code","source":"# test set\neval_df['input'] = 'TEXT1: ' + eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor\neval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:25.504106Z","iopub.execute_input":"2025-09-03T20:46:25.504349Z","iopub.status.idle":"2025-09-03T20:46:25.552378Z","shell.execute_reply.started":"2025-09-03T20:46:25.504333Z","shell.execute_reply":"2025-09-03T20:46:25.551672Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/36 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35264757261c42809089b62da32bfbb4"}},"metadata":{}}],"execution_count":28},{"cell_type":"markdown","source":"# Metrics and correlation","metadata":{}},{"cell_type":"markdown","source":"The competition mentions the evaluation will be done using the Pearson correlation coefficient between the predicted and actual similarity scores.\nTransformers expects metrics to be returned as a dict, since that way the trainer knows what label to use.","metadata":{}},{"cell_type":"code","source":"def corr(x,y): return np.corrcoef(x,y)[0][1]\ndef corr_d(eval_pred): return {'pearson': corr(*eval_pred)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:25.553213Z","iopub.execute_input":"2025-09-03T20:46:25.553409Z","iopub.status.idle":"2025-09-03T20:46:25.557580Z","shell.execute_reply.started":"2025-09-03T20:46:25.553395Z","shell.execute_reply":"2025-09-03T20:46:25.556882Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"To train our model, we'll need these from transformers:","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments,Trainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:25.558344Z","iopub.execute_input":"2025-09-03T20:46:25.558532Z","iopub.status.idle":"2025-09-03T20:46:25.865508Z","shell.execute_reply.started":"2025-09-03T20:46:25.558518Z","shell.execute_reply":"2025-09-03T20:46:25.864765Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"from transformers import TrainingArguments\nprint(TrainingArguments.__init__.__code__.co_varnames)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:25.866371Z","iopub.execute_input":"2025-09-03T20:46:25.866942Z","iopub.status.idle":"2025-09-03T20:46:25.871451Z","shell.execute_reply.started":"2025-09-03T20:46:25.866914Z","shell.execute_reply":"2025-09-03T20:46:25.870617Z"}},"outputs":[{"name":"stdout","text":"('self', 'output_dir', 'overwrite_output_dir', 'do_train', 'do_eval', 'do_predict', 'eval_strategy', 'prediction_loss_only', 'per_device_train_batch_size', 'per_device_eval_batch_size', 'per_gpu_train_batch_size', 'per_gpu_eval_batch_size', 'gradient_accumulation_steps', 'eval_accumulation_steps', 'eval_delay', 'torch_empty_cache_steps', 'learning_rate', 'weight_decay', 'adam_beta1', 'adam_beta2', 'adam_epsilon', 'max_grad_norm', 'num_train_epochs', 'max_steps', 'lr_scheduler_type', 'lr_scheduler_kwargs', 'warmup_ratio', 'warmup_steps', 'log_level', 'log_level_replica', 'log_on_each_node', 'logging_dir', 'logging_strategy', 'logging_first_step', 'logging_steps', 'logging_nan_inf_filter', 'save_strategy', 'save_steps', 'save_total_limit', 'save_safetensors', 'save_on_each_node', 'save_only_model', 'restore_callback_states_from_checkpoint', 'no_cuda', 'use_cpu', 'use_mps_device', 'seed', 'data_seed', 'jit_mode_eval', 'use_ipex', 'bf16', 'fp16', 'fp16_opt_level', 'half_precision_backend', 'bf16_full_eval', 'fp16_full_eval', 'tf32', 'local_rank', 'ddp_backend', 'tpu_num_cores', 'tpu_metrics_debug', 'debug', 'dataloader_drop_last', 'eval_steps', 'dataloader_num_workers', 'dataloader_prefetch_factor', 'past_index', 'run_name', 'disable_tqdm', 'remove_unused_columns', 'label_names', 'load_best_model_at_end', 'metric_for_best_model', 'greater_is_better', 'ignore_data_skip', 'fsdp', 'fsdp_min_num_params', 'fsdp_config', 'fsdp_transformer_layer_cls_to_wrap', 'accelerator_config', 'deepspeed', 'label_smoothing_factor', 'optim', 'optim_args', 'adafactor', 'group_by_length', 'length_column_name', 'report_to', 'ddp_find_unused_parameters', 'ddp_bucket_cap_mb', 'ddp_broadcast_buffers', 'dataloader_pin_memory', 'dataloader_persistent_workers', 'skip_memory_metrics', 'use_legacy_prediction_loop', 'push_to_hub', 'resume_from_checkpoint', 'hub_model_id', 'hub_strategy', 'hub_token', 'hub_private_repo', 'hub_always_push', 'gradient_checkpointing', 'gradient_checkpointing_kwargs', 'include_inputs_for_metrics', 'include_for_metrics', 'eval_do_concat_batches', 'fp16_backend', 'push_to_hub_model_id', 'push_to_hub_organization', 'push_to_hub_token', 'mp_parameters', 'auto_find_batch_size', 'full_determinism', 'torchdynamo', 'ray_scope', 'ddp_timeout', 'torch_compile', 'torch_compile_backend', 'torch_compile_mode', 'include_tokens_per_second', 'include_num_input_tokens_seen', 'neftune_noise_alpha', 'optim_target_modules', 'batch_eval_metrics', 'eval_on_start', 'use_liger_kernel', 'eval_use_gather_object', 'average_tokens_across_devices')\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"We use batch size, which fits the GPU, and use small number of epochs for faster training.","metadata":{}},{"cell_type":"code","source":"bs = 128\nepochs = 5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:25.872273Z","iopub.execute_input":"2025-09-03T20:46:25.872490Z","iopub.status.idle":"2025-09-03T20:46:25.882821Z","shell.execute_reply.started":"2025-09-03T20:46:25.872474Z","shell.execute_reply":"2025-09-03T20:46:25.882087Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"lr = 8e-5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:25.883586Z","iopub.execute_input":"2025-09-03T20:46:25.883820Z","iopub.status.idle":"2025-09-03T20:46:25.893300Z","shell.execute_reply.started":"2025-09-03T20:46:25.883804Z","shell.execute_reply":"2025-09-03T20:46:25.892762Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"Transformers uses the TrainingArguments class to set up arguments.","metadata":{}},{"cell_type":"code","source":"args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n    eval_strategy=\"epoch\", logging_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n    num_train_epochs=epochs, weight_decay=0.01, report_to='none')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:25.894058Z","iopub.execute_input":"2025-09-03T20:46:25.894331Z","iopub.status.idle":"2025-09-03T20:46:25.932524Z","shell.execute_reply.started":"2025-09-03T20:46:25.894306Z","shell.execute_reply":"2025-09-03T20:46:25.932042Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\ntrainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n                  tokenizer=tokz, compute_metrics=corr_d)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:25.933279Z","iopub.execute_input":"2025-09-03T20:46:25.933448Z","iopub.status.idle":"2025-09-03T20:46:26.229345Z","shell.execute_reply.started":"2025-09-03T20:46:25.933435Z","shell.execute_reply":"2025-09-03T20:46:26.228570Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_3382/4180054943.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"trainer.train();","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:46:26.230217Z","iopub.execute_input":"2025-09-03T20:46:26.230442Z","iopub.status.idle":"2025-09-03T20:52:34.409755Z","shell.execute_reply.started":"2025-09-03T20:46:26.230425Z","shell.execute_reply":"2025-09-03T20:52:34.409075Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='535' max='535' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [535/535 06:06, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Pearson</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.068000</td>\n      <td>0.030250</td>\n      <td>0.774524</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.029000</td>\n      <td>0.025263</td>\n      <td>0.792014</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.020000</td>\n      <td>0.022544</td>\n      <td>0.821885</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.015200</td>\n      <td>0.023553</td>\n      <td>0.830098</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.013000</td>\n      <td>0.022942</td>\n      <td>0.831233</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"preds = trainer.predict(eval_ds).predictions.astype(float)\npreds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:52:34.410475Z","iopub.execute_input":"2025-09-03T20:52:34.410689Z","iopub.status.idle":"2025-09-03T20:52:34.510307Z","shell.execute_reply.started":"2025-09-03T20:52:34.410663Z","shell.execute_reply":"2025-09-03T20:52:34.509764Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"array([[ 0.50079411],\n       [ 0.69522429],\n       [ 0.6164003 ],\n       [ 0.34443745],\n       [-0.04182976],\n       [ 0.53344709],\n       [ 0.5098325 ],\n       [-0.01717768],\n       [ 0.27085549],\n       [ 1.10770631],\n       [ 0.26348093],\n       [ 0.23570023],\n       [ 0.78616691],\n       [ 1.01833248],\n       [ 0.74594665],\n       [ 0.3691071 ],\n       [ 0.26086798],\n       [-0.05681508],\n       [ 0.62070602],\n       [ 0.36089557],\n       [ 0.48032713],\n       [ 0.26338986],\n       [ 0.15293182],\n       [ 0.23470487],\n       [ 0.55423379],\n       [-0.02562906],\n       [-0.05165453],\n       [-0.03737988],\n       [-0.04751722],\n       [ 0.73212296],\n       [ 0.31206596],\n       [ 0.03996582],\n       [ 0.69898397],\n       [ 0.50855434],\n       [ 0.47621   ],\n       [ 0.21128435]])"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"preds = np.clip(preds, 0, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:52:34.511080Z","iopub.execute_input":"2025-09-03T20:52:34.511383Z","iopub.status.idle":"2025-09-03T20:52:34.515346Z","shell.execute_reply.started":"2025-09-03T20:52:34.511361Z","shell.execute_reply":"2025-09-03T20:52:34.514520Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:52:34.516195Z","iopub.execute_input":"2025-09-03T20:52:34.516384Z","iopub.status.idle":"2025-09-03T20:52:34.528263Z","shell.execute_reply.started":"2025-09-03T20:52:34.516369Z","shell.execute_reply":"2025-09-03T20:52:34.527626Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"array([[0.50079411],\n       [0.69522429],\n       [0.6164003 ],\n       [0.34443745],\n       [0.        ],\n       [0.53344709],\n       [0.5098325 ],\n       [0.        ],\n       [0.27085549],\n       [1.        ],\n       [0.26348093],\n       [0.23570023],\n       [0.78616691],\n       [1.        ],\n       [0.74594665],\n       [0.3691071 ],\n       [0.26086798],\n       [0.        ],\n       [0.62070602],\n       [0.36089557],\n       [0.48032713],\n       [0.26338986],\n       [0.15293182],\n       [0.23470487],\n       [0.55423379],\n       [0.        ],\n       [0.        ],\n       [0.        ],\n       [0.        ],\n       [0.73212296],\n       [0.31206596],\n       [0.03996582],\n       [0.69898397],\n       [0.50855434],\n       [0.47621   ],\n       [0.21128435]])"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"import datasets\n\nsubmission = datasets.Dataset.from_dict({\n    'id': eval_ds['id'],\n    'score': preds.flatten()\n})\n\nsubmission.to_csv(\"/kaggle/working/submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:52:34.529007Z","iopub.execute_input":"2025-09-03T20:52:34.529646Z","iopub.status.idle":"2025-09-03T20:52:34.561591Z","shell.execute_reply.started":"2025-09-03T20:52:34.529623Z","shell.execute_reply":"2025-09-03T20:52:34.560895Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccc3c98a95e34729a57882bfe1d2c25f"}},"metadata":{}},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"1178"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"submission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:52:34.562385Z","iopub.execute_input":"2025-09-03T20:52:34.562571Z","iopub.status.idle":"2025-09-03T20:52:34.567217Z","shell.execute_reply.started":"2025-09-03T20:52:34.562557Z","shell.execute_reply":"2025-09-03T20:52:34.566460Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'score'],\n    num_rows: 36\n})"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"# Reload the saved submission\ncheck = pd.read_csv(\"submission.csv\")\n\nprint(\"Shape:\", check.shape)\nprint(\"Dtypes:\\n\", check.dtypes)\nprint(\"\\nFirst few rows:\")\nprint(check.head())\n\n# Checks\nassert \"id\" in check.columns, \"Missing 'id' column\"\nassert \"score\" in check.columns, \"Missing 'score' column\"\nassert check['score'].dtype in [float, 'float64'], \"Scores must be floats\"\nassert not check['score'].isnull().any(), \"Found NaNs in scores\"\nassert check['id'].equals(eval_df['id']), \"IDs don't match test.csv order\"\nprint(\"\\n✅ Submission file is Kaggle-ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:52:34.568025Z","iopub.execute_input":"2025-09-03T20:52:34.568239Z","iopub.status.idle":"2025-09-03T20:52:34.581389Z","shell.execute_reply.started":"2025-09-03T20:52:34.568218Z","shell.execute_reply":"2025-09-03T20:52:34.580819Z"}},"outputs":[{"name":"stdout","text":"Shape: (36, 2)\nDtypes:\n id        object\nscore    float64\ndtype: object\n\nFirst few rows:\n                 id     score\n0  4112d61851461f60  0.500794\n1  09e418c93a776564  0.695224\n2  36baf228038e314b  0.616400\n3  1f37ead645e7f0c8  0.344437\n4  71a5b6ad068d531f  0.000000\n\n✅ Submission file is Kaggle-ready!\n","output_type":"stream"}],"execution_count":42}]}